%
% "The UCD CASL SenseTile System", for IEEE Pervasive Computing
% Joseph R. Kiniry, Vieri del Bianco, Dragan Stosic
% $Id: paper.tex 2795 2007-09-23 19:35:53Z dmz 
%

\documentclass{article} 
\usepackage{times}

\usepackage{ifpdf}
\usepackage{a4wide}
\usepackage{pdfsync}

\ifpdf
\usepackage[pdftex]{graphicx}
\else
\usepackage{graphicx}
\fi

\usepackage{xspace}
\usepackage{tabularx}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{eucal}
\usepackage{stmaryrd}
\usepackage{float}
\usepackage{listings}
\input{jml-listings}
\lstset{language=[JML]Java,xleftmargin=20pt,xrightmargin=20pt}

\ifpdf
\usepackage[pdftex,bookmarks=false,a4paper=false,
            plainpages=false,naturalnames=true,
            colorlinks=true,pdfstartview=FitV,
            linkcolor=blue,citecolor=blue,urlcolor=blue,
            pdfauthor="Joseph R. Kiniry and Vieri del Bianco and Dragan
Stosic"]{hyperref}
\else
\usepackage[dvips,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\fi

\newcommand{\tablesize}{\footnotesize}
\newcommand{\eg}{e.g.,\xspace}
\newcommand{\ie}{i.e.,\xspace}
\newcommand{\etc}{etc.\xspace}
\newcommand{\myhref}[2]{\ifpdf\href{#1}{#2}\else\htmladdnormallinkfoot{#2}{#1}\fi}
\newcommand{\myhreffootnote}[3]{\myhref{#1}{#2}\footnote{#3 \myhref{#1}{#1}}}

\newcommand{\lil}[1]{\texttt{\lstinline|#1|}}

\newcommand{\notev}[1]{\xspace$\textcolor{blue}{\omega^\textsf{vieri}}$\marginpar{\scriptsize\textsf{Vieri:} #1}}
\newcommand{\notej}[1]{\xspace$\frac{\varocircle}{\textsf{jk}}$\marginpar{\scriptsize\textsf{Joe:} #1}}
\newcommand{\noted}[1]{\xspace$\textcolor{red}{\dagger^\textsf{dragan}}$\marginpar{\scriptsize\textsf{Dragan:} #1}}

\newcommand{\todo}{\textbf{TODO:}}

\newcommand{\ST}{\emph{SenseTile}\xspace}
\newcommand{\STSB}{\ST \emph{Sensor Board}\xspace}
\newcommand{\STSBs}{\ST \emph{Sensor Boards}\xspace}
\newcommand{\STPU}{\ST \emph{Processor Unit}\xspace}
\newcommand{\STPUs}{\ST \emph{Processor Units}\xspace}
\newcommand{\STU}{\ST \emph{Unit}\xspace}
\newcommand{\STUs}{\ST \emph{Unit}\xspace}

\newcommand{\STs}{\emph{SenseTiles}\xspace}

\newcommand{\simulator}{\STSB \emph{Simulator}\xspace}

\newcommand{\datastore}{\ST Scientific Datastore\xspace}
\newcommand{\computefarm}{The \ST Scientific Compute Farm\xspace}
\newcommand{\computefarmlong}{UCD CASL \ST Software and Data Compute Server
Farm\xspace}
\newcommand{\sensorfarm}{The \STSBs\xspace}

%---------------------------------------------------------------------
% New commands, macros, \etc
%---------------------------------------------------------------------

%% \input{kt}

%=====================================================================

\begin{document}

\title{Deriving an Executable Model of a Data Stream Protocol from its
Specification}

\author{Joseph R. Kiniry, Vieri del Bianco, Dragan Stosic\\
UCD CASL: Complex and Adaptive Systems Laboratory and\\
School of Computer Science and Informatics,\\
University College Dublin,\\
Belfield, Dublin 4, Ireland,\\
kiniry@acm.org, vieri.delbianco@gmail.com, dragan.stosic@gmail.com\\
}

\maketitle

%======================================================================
%\thispagestyle{empty}
\begin{abstract}

\begin{verbatim}

OBJECTIVE: 
Specifications used as a blueprint for system development.
Specifications to generate test suite to validate the developed system.
Specifications to validate simulator of the developed system.
Apply to data stream processing: verify the stream is parsed correctly, 
verify the parsed stream output stream can be simulated.

METHODS: 
JML model.
JML tools to generate JUnit test suite.
JUnit test suite applied to developed system, to verify its correctness.
JUnit test suite applied to simulator, to verify its correctness.

RESULTS: 
Proof developed system same behavior as simulator.
Proof developed system and simulator verify the specifications.

CONCLUSIONS:
Specifications serves two purposes, and indirectly a third one.

\end{verbatim}

  Sensor equipped devices typically communicate with a streaming packet-based 
  network protocol.
  The communication is focused on controlling the sensors and report the 
  sensors measurements.
  The \STSB is an example of such a device, it communicates with an arbitrary 
  computer system, the \STPU (running Linux or Windows, at the moment) over 
  a USB bus using a streaming packet-based protocol.
  The \STU is a custom-designed, but inexpensive, sensor platform: it is 
  composed by a one or more \STSBs paired with a general-purpose small-scale 
  compute node, the \STPU (including everything from PDAs to powerful 
  touchscreen-based portable computers).
  There are over a dozen sensors on the \STSB itself, and new sensors can be 
  added either using expansion slots on the \STSB, or adding them directly to 
  the USB bus.
  A third-party low-level library, provided by the USB chip vendor, the USB 
  chip that has been used in the \STSB, creates and parses
  generic USB communication packets.

  A custom medium-level Java driver creates and parses the \STSB streaming 
  communication packets. 
  The driver is formally specified, validated and verified with rigorous
  unit testing. 
  Because of this process and combination of technologies, using this
  specification we are able to both communicate with a real \ST
  \textbf{and} generate a formally specified, executable, functional
  model-based specification for the protocol itself written in the
  Java Modeling Language.
  \notev{executable? how? what does this mean?}
  This protocol model is itself an executable
  stream simulator that can be used to develop new \ST user
  applications without having the \ST hardware at all. 
  Consequently,
  from this single specification, we can test that the \ST hardware
  communicates as expected, test that our \ST simulator communicates
  as expected, and simulate the \ST protocol stream itself.

\end{abstract}



%======================================================================
\section{Introduction}

The \textbf{UCD CASL SenseTile System} is a large-scale, general-purpose
sensor system to be installed at the University College Dublin in Dublin,
Ireland. 
Our facility aims to provide a scalable and extensible 
infrastructure for performing in-depth investigation of both the specific 
and general issues in large-scale sensor networking.

This system integrates a sensor platform, a datastore, and a compute
farm.  
The sensor platform is a custom-designed, but inexpensive,
sensor platform (called the \ST) paired with general-purpose
small-scale compute nodes, including everything from low-power PDAs to
powerful touchscreen-based portable computers. 
There are over a dozen
sensors on the \ST itself, and new sensors can be added by adding them
to the board.

Because of hard time constraints, and the initial unavailability of the 
custom board, we needed to progress concurrently with all the development tasks: 
the specification of the communication protocol with the \STSB, the development of 
the controlling code in the \STSB, the development of the driver to communicate 
with the \STSB, and the development of the simulators needed for future tests 
of the system (the controlling code of the board was developed by the external 
manufacturer of the board, hence, it is not taken into account here).

\todo explain and refine the problem

\todo search: other approaches to similar problems

To tackle the complexity of the concurrent tasks the formal model of the protocol 
was used as a focus point that led all the other development tasks. 
The formal model of the protocol was used to check at run time the correctness of 
the /SB, the driver, the simulator, and the hand made test suites of the driver 
and the simulator.
The formal model was used to automatically generate a test suite to verify that
both the driver and the simulator were compliant to the specification, and eventually 
to verify the specification itself.

The approach proved itself effective, at the point that, when the board was finally 
released, no defects were found in the driver or the simulator, while the errors and 
not agreed changes introduced in the board where discovered during the first execution.

\paragraph*{Outline}

In section \ref{sec:data_stream_and_protocol_description} the data stream model 
and protocol is presented.

In section \ref{sec:data_stream_and_protocol_specification} the data stream model 
and protocol is specified.

In section \ref{sec:test_cases} the test cases structure is presented, for 
both the hand made and the generated ones. 
Both the approaches are analyzed, their pro and contra are discussed, as 
well as the expected advantages to use them in combination.

In section \ref{sec:test_cases_on_the_job} the execution of the test suites
is described, the data collected is presented.

In section \ref{sec:test_cases_retrospectives} the data collected is analyzed, 
both from a qualitative and a quantitative points of view.

In section \ref{sec:test_cases_and_the_scenarios} the different scenarios on 
which test cases based on specifications can be applied are analyzed, and 
the resulting benefits it is possible to obtain are detailed.

In section \ref{sec:related_works} related works are presented and analyzed.

Finally in section \ref{sec:conclusion} conclusions are drawed and 
ongoing and future works on similar topics is introduced.



%=====================================================================
\section{Data stream and protocol description}
\label{sec:data_stream_and_protocol_description}

The communication between \STSB and \STPU is realized through an Universal 
Serial Bus (USB) interface.
On top of the USB serial channels a proprietary protocol is used, specified by 
FTDI\footnote{\myhref{http://www.ftdichip.com/}{FTDI web site}}; FTDI is the 
manufacturer of the USB controller chip used in the \STSB, the 
FT2232H\cite{ftdi_ft232h_2009}.

The proprietary protocol enables the control and management of some of the 
functionalities in FT232H chip (such as internal EEPROM read and write, reset 
the chip, etc.) as well as the definition of the communication protocol and 
properties to be used in the asynchronous channels (input and output channels) 
provided by FT232H.
These added functionalities are accessed via an Application Program Interface,
the API is provided by a driver developed directly by FTDI, which is available 
for various systems (Linux 32 and 64 bits, Mac OS, Windows)
\cite{ftdi_d2xx_api_2009}.

Finally, on top of the serial channels provided by the API, a custom protocol 
has been developed to manage the entire \STSB; that is, read sensor data 
observations, enable or disable sensors, configure on-board components 
as the Field-Programmable Gate Array (FPGA), and the micro processor; the 
protocol main function is to read sensor data.

The protocol is an asynchronous fixed length packed based protocol.
The protocol has been divided in multiple layers to ease its formal description.
The rationale is the following: mixing up different abstraction levels of a 
protocol description can lead to overly complex and unmanageable descriptions, 
expecially when dealing with formal ones.
The layers identified in protocol are the following:

\begin{description}
 \item[Packet byte structure]: the internal representation of the packet.
 \item[Packet info structure]: the meaningful fields contained in the packets.
 \item[Single packet rules]: the content acceptable values, and how they 
influence each other.
 \item[Packet sequence rules]: the content acceptable values, based on values 
of previously received packets.
 \item[Packet input output asynchronous rules]: the content acceptable values 
and reaction constraints on output packets, based on previously transmitted 
input packets.
\end{description}

We will only examine the output sensor data packet, since it is the more used 
and interesting one.
We will examine the first three layers, that is: the packet byte structure, the 
packet info structure and the single packet rules.

The packet byte and info structures of the output sensor data packet reflects the board 
capabilities and sensors.
Basically a single packet has to accommodate various types of data:
\begin{itemize}
 \item Fast data rate streams: audio data, 48KHz or 96KHz.
 \item Medium data rate streams: 5KHz.
 \item Slow data rate streams: temperature, pression, accelerometer, etc.; all 
 these sensor have a data rate far lower than 5 KHz.
 \item Metadatas: metadatas on sensors and board state.
\end{itemize}

Even if we have to deal with data streams that have different data rates, the 
internal structure of the package (as we will see) is strictly fixed. 
This choice originates from a trade-off between two constraints: the efficiency 
of the transmission (redundant data to be minimized) and the complexity to build 
a package (complexity to be minimized).
The complexity minimization constraint rationale is the following: the FPGA 
on the \STSB builds the packet, but the FPGA is also to be used for various 
other specific tasks; it is important to maintain the building packet code on the 
FPGA as simple and short as possible, to leave enough space to implement other 
tasks.
The Output sensor data packet structure is showed in Table 
\ref{tab:data_packet_structure}, the packet total length is 1024 bytes (512 16 
bit words).

\begin{table}[htbp]
\caption{Output sensor data packet structure.}
\label{tab:data_packet_structure}
\begin{center}
\begin{tabular}{|c|l|}\hline
\textbf{\textit{index}} & \textbf{\textit{function}}\\\hline
0-1 & sentinel\\\hline
2-7 & slow data\\\hline
8-11 & metadata: board state\\\hline
12-13 & reserved\\\hline
14-15 & metadata: board state\\\hline
16 & reserved\\\hline
17-22 & frame 1\\\hline
\ldots & \ldots\\\hline
503-508 & subsequence 82\\\hline
\end{tabular}
\end{center}
\end{table}

The frames accommodate data from the fast and medium data rate streams 
(there are 4 fast data rate stream and 8 medium data rate stream channels). 
There are 82 frames in a packet.
The frame structure is shown in Table \ref{tab:subsequence_structure}.

\begin{table}[htbp]
\caption{Output sensor data packet subsequence structure.}
\label{tab:subsequence_structure}
\begin{center}
\begin{tabular}{|c|l|}\hline
\textbf{\textit{index}} & \textbf{\textit{function}}\\\hline
0 & metadata: subsequence description\\\hline
1 & medium data rate data sample\\\hline
2-5 & fast data rate data samples\\\hline
\end{tabular}
\end{center}
\end{table}

Looking at the structure described and at the data rates frequencies, it
can be seen that there must be something subtle, to make all the figures to 
add up, that is, to be capable to accommodate three different rates outputs
in a fixed structure, fixed length packet.
The subtleties lies in two forms of redundancies, for slow and medium data 
rates:

\begin{itemize}
  \item Slow data rates: slow data can be found at the beginning of each 
  packet, the data is simply repeated (that is, it is equal to the previous 
  packet in the stream) when no new data is available.
  \item Medium data rates: the 8 medium rate channels are multiplexed together 
  into the medium data rate data sample of each subsequence, which channel the 
  sample belongs to is a piece of info to be extracted from the subsequence 
  metadata. Besides, the medium data rate data sample could contain no data at 
  all, this info again is to be extracted from the metadata.
\end{itemize}

The single packet rules delimit the boundaries of the values obtainable from 
the packet: each defined sensor represented in the packet, as well as the 
metadata describing the \STSB and the packet and frame contents,  have a defined 
range of acceptable values.
There are also rules affecting more than one value, basically validity rules (i.e. if 
a specific sensor is active than the reading value has to be in a defined range), 
and rules specifing a correct sequence of frames (i.e. there can be only one switch 
in sampling rate in the frame sequence of a single packet).



%=====================================================================
\section{Data stream and protocol specification}
\label{sec:data_stream_and_protocol_specification}

The specification of the protocol has been used as a focus point to lead all the 
other development tasks.

We needed a specification capable of:

\begin{itemize}
 \item Be executed at run time. If something on the protocol is not respected, 
the run time execution environment is capable to detect and signal the fault.
 \item Generate tests. 
 \item Verify simulators.
 \item Be used in conjunction of hand written unit tests.
\end{itemize}

We also needed a specification capable to tackle properly all the protocol layers.
Since the different layers have very different characteristics, different context
dependant specification approaches were chosen.

\paragraph{Packet byte structure specification}

The specification is provided by a reference Java implementation capable of 
recognizing the proper packet structure in a byte data stream. The implementation 
is tricky, since it checks for the sentinels repeatedly to be sufficiently confidant
that the byte stream can be properly decomposed into a packet stream.

The implementation can be obviously executed at run time (the specification is the 
implementation code). 
Meaningful automatic tests cannot be generated. 
The implementation can be used to verify a packet byte structure simulator. 
The implementation were actually driven (Test Driven Development) by the test suite.

\paragraph{Packet info structure specification}

The specification is provided both by the Java API that has been built, and by the 
annotation with JML language\footnote{
\myhref{http://www.cs.ucf.edu/~leavens/JML/}{The Java Modeling Language (JML)}}. 
JML has been chosen because it is capable to specify Java code: JML is a behavioral 
interface specification language. 
JML specification language combines the design by contract approach (applayed to 
Java language) and the model-based specification approach of interface specification 
languages. 

\todo insert proper JML references

Many tools are available supporting JML specification language, focusing on different 
aspects of the language. 
JML2 suite of tools
\footnote{\myhref{http://sourceforge.net/projects/jmlspecs/}{Common JML tools}}
was chosen, since both run time verification support and test generation support are 
provided directly by the suite.

\todo insert proper JML2 references

The Java API specification part is checked automatically by the Java compiler, while
the JML specification part can be checked at run time using the provided JML2 run time 
environment. 
Meaningful automatic tests can be generated from the JML specification. 
The JML specification can be used to verify an abstract packet generation simulator, 
making the simulator an extension of the Java interfaces. 
The specification can also be used to verify the real driver implementation, based on 
the packet byte structure implementation presented above. 
The implementation was driven by the JML specification and by an hand made test suite.
Finally, hand made unit tests can be checked, during execution, against the 
specification, using the provided JML2 run time environment.

\paragraph{Single packet rules}

The specification is provided exclusively by annotations with JML language. 

The capabilities of a JML specification have been already descibed in the previous 
paragraph, that is: specification checkable at run time, tests generation, simulator 
verification, usable with hand written tests.

\subsection{On simulators}
\label{subsec:on_simulators}

Simulators are needed to test in isolation parts of the system; especially the upper 
layers, yet to be developed. 
During the development the simulators were essential, since the board was not available.
Simulators were built concurrently with the specification, the real driver code, and the 
tests.

Theoretically a separate simulator should be needed for each protocol layer; a
separate simulator for each layer would enable us to separeately specify, develop and test
each layer of the protocol.
In our case we evaluated not worth the effort to maintain such a separation in the 
simulators, motivated by the fact that the protocol layers identified are too fine grained 
to be separated into different simulators. 
Two simulators were built.

The two simulators were built reflecting the software abstraction layers defined for the 
driver.
The driver API is splitted in two structurual layers: the general high level interfaces, that 
expose the main functionalities of the board and the main contents of the packets hiding the 
details, and the lower level implementation that parse the data streams in and out the board, 
to translate the higher level intructions and data in properly formed packets.
Hence, we have implemented two simulators: one high level simulator, whicj reimplements the 
high level interfaces providing corresponding high level mechanisms to control the data and 
the behaviour of the simulated board, it has nothing to do with the details of the data 
streams.
One low level simulator which is capable to rebuild the data stream out of the board based on 
the data stream into the board, the in and out data streams are built exaclty as the sensor 
board is expected to be able to parse or generate.

\subsection{JML specification examples}
\label{subsec:a_jml_specification_example}

The JML specifications used to annotate Java code are of varing complexities.
Some of the specifications are simple, focusing on constraints that should hold when 
calling a method (preconditions) and the constraints on the return value (a very basic form of 
postconditions).
In listing \ref{lst:jml_example_simple} a simple JML specification example is shown, the 
method \lil{getTemperature} is declared to be \lil{/*@ pure @*/}, which means that 
it cannot change the state of any object (a postcondition), the specification also constraints 
the return value with a lower and upper bound (another postcondition).

\begin{lstlisting}[
  caption={A simple specification with JML annotation: simple postconditions.},
  label=lst:jml_example_simple,
  float=htbp]
/*@ 
  ensures \result >= -880;
  ensures \result <= 2047;
@*/
/*@ pure @*/ short getTemperature();
\end{lstlisting}

\sloppy

Some of the specifications are rather complex, usually focusing on properties regarding the 
behaviour of a whole object.
In listing \ref{lst:jml_example_invariant} a complex invariant 
(a property that has to be maintained, that is, that is assumed on entry and guaranteed on 
exit of each method of an object)
example is shown. 
The invariant is constraining the number of samples for each medium data rate streams: 
the total number of streams is \lil{Frame.ADC_CHANNELS}, the total number of frames is 
\lil{FRAMS}, the constant constraining the number of samples is 
\lil{FRAMES/Frame.ADC_CHANNELS+1}, meaning that the samples contained in a frame are
fairly distributed on the channels. 
The valid samples are counted parsing all the frames contained in a packet, selecting only 
the matching valid samples.
A medium data rate stream sample is considered valid when \lil{isADCActive()} method 
returns \lil{true}.

\fussy

\begin{lstlisting}[
  caption={A specification with JML annotation: a complex object invariant which constraints 
    the number of samples for each medium data rate stream channel.},
  label=lst:jml_example_invariant,
  float=htbp]
/*@ 
  invariant (
    \forall int channel;
    0 <= channel && channel < Frame.ADC_CHANNELS; 
    (
      \num_of int i;
      0<= i && i<(FRAMES-1);
      (
        getFrame(i).isADCActive() &&
        (getFrame(i).getADCChannel() == channel)
      )
    ) <= (FRAMES / Frame.ADC_CHANNELS + 1)
  );
@*/
\end{lstlisting}



%=====================================================================
\section{Test cases}
\label{sec:test_cases}

The unit test cases that have been built to verify the protocol driver 
are of two kinds: hand made unit tests and unit tests automatically 
generated based on JML specifications.
The tests have been tought to be used together, complementarly. 
Despite of this premise, the tests effectiveness has been evaluated 
separately and together, the evaluation is carried out in section 
\ref{sec:test_cases_retrospectives}.
The test effectiveness evaluation has been based on three elements:
code coverage (quantitative), development help and usefulness 
(qualitative), effective results on piloting the real board 
(quantitative).

The dual testing approach was thought as a winning option when 
compared to hand based tests or completely automated tests, in testing 
a driver for a stream communication protocol with hard constraints 
on development time.
\ST stream communication protocol is characterized by a well definite 
packet structure, and a well definite semantic on the packet contents 
as well.
On the other hand there are not strong constraints on synchronization, 
since there exists two concurrent communication channels and the protocol 
is asynchronous by construction.
The lack of hard synchronization constraints reduce the advantage to use 
a classical state machine based specification. 

\todo reference to protocol tests generated from a state machine based 
specification is needed

Hard development time constraints were also a precise requirement; the time 
constraints pushed us towards a specification \emph{just good enough} for
our purposes.
A \emph{just good enough} specification is simply a specification that is not 
specifing everything, but only the software parts that are considered most 
critical, or the ones that are really easy to specify with the chosen 
specification language.
In \STSB driver JML was used to specify very simple behaviours (method 
oriented) on the whole driver implementaion, and more complex behaviour on 
the driver core interfaces.
The not covered areas were addressed by hand made unit tests.

Hand made unit tests cover behaviour not covered by the automatically 
generated tests, that is, they cover the not specified behaviour; but this 
is not the only purpose they have.
Hand made unit tests are used to drive the development, using the well known 
Test Driven Development approach, as well as to drive the most error prone 
specification as well.
Tests are used to drive the specification, a hand made unit test that should 
fail if the specification is not working as expected.


The rationale is the following: a stream communication protocol is 
not completely focused on a synchronised interaction

\begin{itemize}
 \item 
\end{itemize}




\todo describe dual approach: hand made tests + generated from 
specification tests

\todo reason about the usual structure oracle-driver-test-stub(s). a simulator is sometimes a 
stub, sometimes a driver, sometimes an oracle...

\todo insert references to testing embedded systems with simulators and/or with driver/stubs

\todo describe hybrid agile and TDD approach: high level informal 
specifications with BON, iterative refinements of code, to distill 
test cases and formal specification of the interfaces

\notev{maybe this part is to be saved for a different paper? BON has 
not been used properly}

\todo describe the necessity to add specification generated tests: to ensure
that specification is sound, to obtain higher coverage

\paragraph*{Hand made tests}

\todo describe hand made tests structure

\todo describe abstract test case and abstract test suite patterns: how to 
write tests against interfaces and/or abstract classes

\paragraph*{Generated tests}

\todo describe the tool that generates the testing

\todo describe the structure of the generates tests


%=====================================================================
\section{Test cases on the job}
\label{sec:test_cases_on_the_job}

\todo report high level analysis of the test suites

\todo describe measures: coverage, number of new bugs found

\todo compare hand made vs generated tests

\todo compare compare coupled approach vs single approaches



%=====================================================================
\section{Retrospective on test cases effectiveness}
\label{sec:test_cases_retrospectives}

The test effectiveness evaluation criteria is of two types. 

\todo describe quantitative: coverage

\todo describe qualitative: errors found, help in design, ...

%=====================================================================
\section{Test cases and the scenarios}
\label{sec:test_cases_and_the_scenarios}

\todo benefit: the approach can be used to test different part of the system
that share the same specifications

\todo testing the protocols layers

\todo testing the simulators

\todo describe general approach: depending at what level (of abstraction) tests 
and specifications are written, it is possible to verify both the simulator and 
the real protocol (isn't this obvious?)


%=====================================================================
\section{Related works}
\label{sec:related_works}

\todo

%=====================================================================
\section{Conclusion}
\label{sec:conclusion}

\todo

%======================================================================
%% \nocite{ex1,ex2}
\bibliographystyle{latex8}
\bibliography{extra,%
              abbrev,%
              ads,%
              category,%
              complexity,%
              hypertext,%
              icsr,%
              knowledge,%
              languages,%
              linguistics,%
              meta,%
              metrics,%
              misc,%
              modeling,%
              modeltheory,%
              reuse,%
              rewriting,%
              softeng,%
              specification,%
              ssr,%
              technology,%
              theory,%
              web,%
              upcoming,%
              upcoming_conferences,%
              conferences,%
              workshops,%
              verification,%
              escjava,%
              jml,%
              nijmegen}

%======================================================================
% Fin

\end{document}



%%% Local Variables: 
%%% mode: latex
%%% eval: 
%%% TeX-master: t
%%% End: 
